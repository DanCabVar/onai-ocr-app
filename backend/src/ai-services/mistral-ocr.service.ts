import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { Mistral } from '@mistralai/mistralai';

export interface OCRResult {
  text: string;
  confidence: number;
  language?: string;
  metadata?: {
    pages?: number;
    [key: string]: any;
  };
}

@Injectable()
export class MistralOCRService {
  private readonly logger = new Logger(MistralOCRService.name);
  private client: Mistral;
  private model: string;
  private visionModel: string;

  constructor(private configService: ConfigService) {
    const apiKey = this.configService.get<string>('MISTRAL_API_KEY');
    if (!apiKey) {
      throw new Error('MISTRAL_API_KEY no est√° configurada');
    }

    this.client = new Mistral({ apiKey });
    this.model = this.configService.get<string>('MISTRAL_OCR_MODEL') || 'mistral-ocr-latest';
    this.visionModel = this.configService.get<string>('MISTRAL_VISION_MODEL') || 'pixtral-12b-latest';
    
    this.logger.log(`Mistral OCR Service inicializado con modelo OCR: ${this.model}, Vision: ${this.visionModel}`);
  }

  /**
   * Extrae texto de una imagen o PDF usando Mistral OCR
   * @param fileUrl - URL p√∫blica del archivo en Google Drive
   * @param mimeType - Tipo MIME del archivo
   * @returns Texto extra√≠do y metadata
   */
  async extractTextFromUrl(
    fileUrl: string,
    mimeType: string,
  ): Promise<OCRResult> {
    try {
      this.logger.log(`Iniciando OCR para archivo tipo: ${mimeType} desde URL`);

      // Determinar si es PDF o imagen seg√∫n el mimeType
      const isPDF = mimeType === 'application/pdf';

      // Estructura correcta seg√∫n documentaci√≥n oficial de Mistral
      // https://docs.mistral.ai/capabilities/document_ai/basic_ocr
      const response = await (this.client as any).ocr.process({
        model: this.model,
        document: isPDF
          ? {
              type: 'document_url',
              documentUrl: fileUrl, // camelCase seg√∫n docs
            }
          : {
              type: 'image_url',
              imageUrl: fileUrl, // camelCase seg√∫n docs
            },
        includeImageBase64: true, // camelCase seg√∫n docs
      });

      // üîç DEBUG: Ver estructura completa de la respuesta
      this.logger.log('=== RESPUESTA COMPLETA DE MISTRAL OCR ===');
      this.logger.log(`Tipo de respuesta: ${typeof response}`);
      this.logger.log(`Propiedades disponibles: ${Object.keys(response).join(', ')}`);
      this.logger.log(JSON.stringify(response, null, 2));
      this.logger.log('=========================================');

      // Extraer el texto del response
      // Mistral OCR devuelve el texto en formato markdown dentro de cada p√°gina
      let extractedText = '';
      
      if (response.pages && Array.isArray(response.pages)) {
        this.logger.log(`‚úÖ Encontradas ${response.pages.length} p√°ginas`);
        
        // Extraer el texto markdown de cada p√°gina
        extractedText = response.pages
          .map((page: any) => {
            // El texto viene en page.markdown (formato Markdown)
            const pageText = page.markdown || page.text || '';
            if (pageText) {
              this.logger.log(`‚úÖ P√°gina ${page.index}: ${pageText.length} caracteres`);
            }
            return pageText;
          })
          .filter((text: string) => text.length > 0)
          .join('\n\n--- P√ÅGINA ---\n\n');
        
        this.logger.log(`‚úÖ Texto total extra√≠do: ${extractedText.length} caracteres`);
      } else if (response.text) {
        this.logger.log('‚úÖ Texto encontrado en response.text');
        extractedText = response.text;
      } else if (response.markdown) {
        this.logger.log('‚úÖ Texto encontrado en response.markdown');
        extractedText = response.markdown;
      } else if (response.content) {
        this.logger.log('‚úÖ Texto encontrado en response.content');
        extractedText = response.content;
      }

      if (!extractedText || extractedText.length === 0) {
        throw new Error('No se pudo extraer texto del documento');
      }

      this.logger.log(`OCR completado. Texto extra√≠do: ${extractedText.length} caracteres`);

      return {
        text: extractedText,
        confidence: 0.95, // Mistral OCR tiene alta confianza
        metadata: {
          model: this.model,
          processedAt: new Date().toISOString(),
          mimeType: mimeType,
        },
      };
    } catch (error) {
      this.logger.error(`Error en OCR: ${error.message}`, error.stack);
      throw new Error(`Error al procesar OCR: ${error.message}`);
    }
  }

  /**
   * Extrae texto usando Pixtral (modelo multimodal/vision)
   * Mejor para documentos con layouts complejos (tablas, columnas, etc.)
   * @param fileUrl - URL p√∫blica del archivo
   * @param mimeType - Tipo MIME del archivo
   * @returns Texto extra√≠do con mejor comprensi√≥n del layout
   */
  async extractTextWithVision(
    fileUrl: string,
    mimeType: string,
  ): Promise<OCRResult> {
    try {
      this.logger.log(`Iniciando extracci√≥n con Vision (Pixtral) para: ${mimeType}`);

      const prompt = `Analiza este documento cuidadosamente y extrae TODO el texto visible.

**INSTRUCCIONES IMPORTANTES:**
1. Respeta el LAYOUT original (columnas, tablas, secciones)
2. Para cada ETIQUETA (campo), busca su VALOR correspondiente
3. Si ves un campo como "Tu nombre:", busca el valor a su derecha o debajo
4. Extrae TODAS las cantidades monetarias, fechas y n√∫meros
5. Mant√©n la estructura del documento (usa markdown si es necesario)

**FORMATO DE SALIDA:**
Para cada par etiqueta-valor, escribe:
[ETIQUETA]: [VALOR]

Por ejemplo:
Tu nombre: John Doe
Email: john@example.com
Monto: $100.00

Extrae TODO el contenido visible del documento.`;

      const response = await this.client.chat.complete({
        model: this.visionModel,
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: prompt,
              },
              {
                type: 'image_url',
                imageUrl: fileUrl,
              },
            ],
          },
        ],
      });

      // Handle both string and ContentChunk[] response types
      const rawContent = response.choices?.[0]?.message?.content || '';
      const extractedText = typeof rawContent === 'string' 
        ? rawContent 
        : rawContent.map((chunk: any) => chunk.text || '').join('');

      this.logger.log(`‚úÖ Vision OCR completado: ${extractedText.length} caracteres`);

      return {
        text: extractedText,
        confidence: 0.90,
        metadata: {
          model: this.visionModel,
          processedAt: new Date().toISOString(),
          mimeType: mimeType,
          method: 'vision',
        },
      };
    } catch (error) {
      this.logger.error(`Error en Vision OCR: ${error.message}`, error.stack);
      throw new Error(`Error al procesar con Vision: ${error.message}`);
    }
  }

  /**
   * M√©todo inteligente que intenta OCR est√°ndar primero,
   * y si no captura suficientes datos, usa Vision (Pixtral)
   * @param fileUrl - URL p√∫blica del archivo
   * @param mimeType - Tipo MIME del archivo
   * @returns Mejor resultado de extracci√≥n
   */
  async extractTextSmart(
    fileUrl: string,
    mimeType: string,
  ): Promise<OCRResult> {
    try {
      // Intentar primero con OCR est√°ndar
      this.logger.log('üîç Intentando OCR est√°ndar...');
      const ocrResult = await this.extractTextFromUrl(fileUrl, mimeType);

      // Verificar si el OCR captur√≥ suficientes datos
      const hasEnoughData = this.validateOCRQuality(ocrResult.text);

      if (hasEnoughData) {
        this.logger.log('‚úÖ OCR est√°ndar captur√≥ suficientes datos');
        return ocrResult;
      }

      // Pixtral Vision solo funciona con im√°genes, NO con PDFs
      const isPDF = mimeType === 'application/pdf';
      
      if (isPDF) {
        this.logger.warn('‚ö†Ô∏è  OCR est√°ndar con baja calidad, pero es PDF (Vision no soporta PDFs). Usando resultado del OCR est√°ndar.');
        return ocrResult;
      }

      // Si el OCR es insuficiente y es una imagen, usar Vision (Pixtral)
      this.logger.warn('‚ö†Ô∏è  OCR est√°ndar insuficiente. Usando Vision (Pixtral)...');
      const visionResult = await this.extractTextWithVision(fileUrl, mimeType);

      return visionResult;
    } catch (error) {
      this.logger.error(`Error en extracci√≥n inteligente: ${error.message}`);
      throw error;
    }
  }

  /**
   * Valida si el texto extra√≠do por OCR tiene suficiente calidad
   * Verifica que no solo capture etiquetas sino tambi√©n valores
   */
  private validateOCRQuality(text: string): boolean {
    // Si el texto es muy corto, probablemente no captur√≥ todo
    if (text.length < 100) {
      return false;
    }

    // Contar l√≠neas que parecen tener valores (contienen n√∫meros, emails, etc.)
    const lines = text.split('\n');
    const linesWithValues = lines.filter(line => {
      // Buscar patrones que indiquen valores reales
      return (
        /\d{2,}/.test(line) ||           // N√∫meros de 2+ d√≠gitos
        /@/.test(line) ||                 // Emails
        /\$\s*\d+/.test(line) ||         // Cantidades monetarias
        /\d{1,2}\/\d{1,2}\/\d{2,4}/.test(line) || // Fechas
        /\d{4}-\d{2}-\d{2}/.test(line)   // Fechas ISO
      );
    });

    // Si menos del 20% de las l√≠neas tienen valores, probablemente solo captur√≥ etiquetas
    const valueRatio = linesWithValues.length / lines.length;
    
    this.logger.log(`üìä Calidad OCR: ${linesWithValues.length}/${lines.length} l√≠neas con valores (${(valueRatio * 100).toFixed(1)}%)`);

    return valueRatio >= 0.2; // Al menos 20% de l√≠neas deben tener valores
  }

  /**
   * Valida si el archivo es compatible con OCR
   */
  isFileTypeSupported(mimeType: string): boolean {
    const supportedTypes = [
      'image/png',
      'image/jpeg',
      'image/jpg',
      'image/webp',
      'application/pdf',
    ];
    return supportedTypes.includes(mimeType);
  }
}

